Metadata-Version: 2.3
Name: neat-llm
Version: 0.1.1a1
Summary: A simpler and more intuitive abstraction for working quickly with Large Language Models (LLMs). Easily create tool-calling agents and generate structured output. Neat aims to making it easier to prototype and build AI-powered applications.
License-File: LICENSE
Keywords: ai,language-model,llm,llm-agents
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Requires-Dist: beautifulsoup4
Requires-Dist: duckduckgo-search
Requires-Dist: instructor>=1.3.7
Requires-Dist: ipykernel>=6.29.5
Requires-Dist: litellm>=1.44.5
Requires-Dist: loguru>=0.7.2
Requires-Dist: numpydoc
Requires-Dist: pydantic-settings>=2.3.4
Requires-Dist: pydantic>=2.8.2
Description-Content-Type: text/markdown

# neat-llm

A simpler abstraction for working with Large Language Models (LLMs).

## Features

- **Unified Interface**: Work with multiple LLM providers (OpenAI, Anthropic, Cohere, Mistral) through a single, consistent API.
- **Prompt Management**: Easily create, version, and reuse prompts (in development).
- **Tool Integration**: Seamlessly integrate custom tools and functions for LLMs to use.
- **Structured Outputs**: Define and validate structured outputs using Pydantic models.
- **Type Safety**: Leverage Python's type hinting for a safer development experience.
- **Flexible Configuration**: Easy-to-use configuration management with environment variable support.
- **Conversation Mode**: Engage in multi-turn dialogues with your agent.

**Note**: Prompt versioning and database features are currently under development. These features may undergo changes in future releases.

## Installation

```bash
pip install neat-llm
```

## API Key Setup

To use neat-llm with various LLM providers, you need to set up the appropriate API keys. You can do this in two ways:

1. Create a `.env` file in your project root with the following content:

   ```
   OPENAI_API_KEY=your_openai_api_key
   ANTHROPIC_API_KEY=your_anthropic_api_key
   COHERE_API_KEY=your_cohere_api_key
   MISTRAL_API_KEY=your_mistral_api_key
   ```


2. Use the `neat_config` object to set API keys programmatically:

   ```python
   from neat import neat_config

   neat_config.openai_api_key = "your_openai_api_key"
   neat_config.anthropic_api_key = "your_anthropic_api_key"
   neat_config.cohere_api_key = "your_cohere_api_key"
   neat_config.mistral_api_key = "your_mistral_api_key"
   ```

Replace `your_*_api_key` with your actual API keys from the respective providers.

## Quick Start

```python
from neat import Neat

neat = Neat()

@neat.lm()
def generate_story(theme: str, length: int):
    return [
        neat.system("You are a creative story writer."),
        neat.user(f"Write a {length}-word story about {theme}."),
    ]

def main():
    story = generate_story("time travel", 100)
    print("Generated Story:")
    print(story)

if __name__ == "__main__":
    main()
```

## Advanced Usage

### Custom Tools

```python
from neat import Neat
from pydantic import BaseModel, Field
import random

neat = Neat()

class WeatherInfo(BaseModel):
    """Represents weather information for a specific location."""
    temperature: float = Field(..., description="Current temperature in Celsius")
    conditions: str = Field(..., description="Brief description of weather conditions")

@neat.tool()
def get_weather(location: str) -> WeatherInfo:
    """Fetch current weather information for a given location."""
    # Simulating weather data for demonstration
    temp = round(random.uniform(0, 35), 1)
    conditions = random.choice(["Sunny", "Cloudy", "Rainy", "Windy"])
    return WeatherInfo(temperature=temp, conditions=conditions)

@neat.lm(tools=[get_weather])
def weather_small_talk():
    return [
        neat.system("You are a friendly AI assistant who can discuss weather. Use the get_weather tool when asked about specific locations."),
        neat.user("How's the weather in New York today? And what about Tokyo?"),
    ]

def main():
    conversation = weather_small_talk()
    print("Weather Small Talk:")
    print(conversation)

if __name__ == "__main__":
    main()
```

### Structured Outputs

```python
from neat import Neat
from pydantic import BaseModel, Field

neat = Neat()

class MovieRecommendation(BaseModel):
    """Represents a movie recommendation with details."""
    title: str = Field(..., description="The title of the recommended movie")
    year: int = Field(..., description="The release year of the movie")
    genre: str = Field(..., description="The primary genre of the movie")
    reason: str = Field(..., description="A brief explanation for why this movie is recommended")

@neat.lm(response_model=MovieRecommendation)
def recommend_movie(preferences: str):
    return [
        neat.system("You are a movie recommendation expert. Provide recommendations based on user preferences."),
        neat.user(f"Recommend a movie based on these preferences: {preferences}"),
    ]

def main():
    preferences = "I like sci-fi movies with mind-bending plots and strong character development"
    movie = recommend_movie(preferences)
    print("Movie Recommendation:")
    print(f"Title: {movie.title} ({movie.year})")
    print(f"Genre: {movie.genre}")
    print(f"Reason: {movie.reason}")

if __name__ == "__main__":
    main()
```

### Conversation Mode

```python
from neat import Neat

neat = Neat()

@neat.lm(conversation=True)
def chat_with_ai():
    return [
        neat.system("You are a friendly and knowledgeable AI assistant. Engage in a conversation with the user, answering their questions and providing helpful information."),
        neat.user("Hello! I'd like to chat about various topics. What shall we discuss?"),
    ]

def main():
    chat_with_ai()  # This will start an interactive conversation

if __name__ == "__main__":
    main()
```

In conversation mode, you'll see a rich console interface with color-coded messages and formatted text. To exit the conversation, simply type "exit" or "quit".

## Documentation

For full documentation, visit [docs.neat-llm.com](https://docs.neat-llm.com).

## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for more details.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- [LiteLLM](https://github.com/BerriAI/litellm) for providing the backend LLM interactions.
- All the amazing LLM providers and researchers pushing the boundaries of AI.