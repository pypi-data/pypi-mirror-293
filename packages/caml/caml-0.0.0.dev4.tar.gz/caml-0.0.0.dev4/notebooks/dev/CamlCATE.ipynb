{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caml API Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "datasets = [\n",
    "    \"partially_linear_simple\",\n",
    "    \"fully_heterogenous\",\n",
    "    \"partially_linear_constant\",\n",
    "    \"dowhy_linear\",\n",
    "]\n",
    "backends = [\"pandas\", \"pyspark\", \"polars\"]\n",
    "\n",
    "df_backend = backends[0]\n",
    "dataset = datasets[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caml.extensions.synthetic_data import (\n",
    "    make_dowhy_linear_dataset,\n",
    "    make_fully_heterogeneous_dataset,\n",
    "    make_partially_linear_dataset_constant,\n",
    "    make_partially_linear_dataset_simple,\n",
    ")\n",
    "\n",
    "if dataset == \"partially_linear_simple\":\n",
    "    df, true_cates, true_ate = make_partially_linear_dataset_simple(\n",
    "        n_obs=1000,\n",
    "        n_confounders=5,\n",
    "        dim_heterogeneity=2,\n",
    "        binary_treatment=True,\n",
    "        seed=None,\n",
    "    )\n",
    "    df[\"true_cates\"] = true_cates\n",
    "elif dataset == \"fully_heterogenous\":\n",
    "    df, true_cates, true_ate = make_fully_heterogeneous_dataset(\n",
    "        n_obs=1000,\n",
    "        n_confounders=10,\n",
    "        theta=4.0,\n",
    "        seed=None,\n",
    "    )\n",
    "    df[\"true_cates\"] = true_cates\n",
    "elif dataset == \"partially_linear_constant\":\n",
    "    df, true_cates, true_ate = make_partially_linear_dataset_constant(\n",
    "        n_obs=1000,\n",
    "        ate=4.0,\n",
    "        n_confounders=5,\n",
    "        dgp=\"make_plr_CCDDHNR2018\",  # make_plr_turrell2018\n",
    "        seed=None,\n",
    "    )\n",
    "    df[\"true_cates\"] = true_cates\n",
    "elif dataset == \"dowhy_linear\":\n",
    "    df, true_cates, true_ate = make_dowhy_linear_dataset(\n",
    "        beta=2.0,\n",
    "        n_obs=1000,\n",
    "        n_confounders=10,\n",
    "        n_discrete_confounders=3,\n",
    "        n_effect_modifiers=6,\n",
    "        n_discrete_effect_modifiers=2,\n",
    "        n_treatments=1,\n",
    "        binary_treatment=False,\n",
    "        categorical_treatment=True,\n",
    "        binary_outcome=False,\n",
    "        seed=0,\n",
    "    )\n",
    "\n",
    "    for i in range(1, len(true_cates) + 1):\n",
    "        if isinstance(true_cates[f\"d{i}\"], list):\n",
    "            df[f\"true_cate_d{i}_1\"] = true_cates[f\"d{i}\"][0]\n",
    "            df[f\"true_cate_d{i}_2\"] = true_cates[f\"d{i}\"][1]\n",
    "        else:\n",
    "            df[f\"true_cate_d{i}\"] = true_cates[f\"d{i}\"]\n",
    "\n",
    "\n",
    "df[\"uuid\"] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "if df_backend == \"polars\":\n",
    "    df = pl.from_pandas(df)\n",
    "    spark = None\n",
    "elif df_backend == \"pandas\":\n",
    "    spark = None\n",
    "    pass\n",
    "elif df_backend == \"pyspark\":\n",
    "    spark = (\n",
    "        SparkSession.builder.master(\"local[1]\")\n",
    "        .appName(\"local-tests\")\n",
    "        .config(\"spark.executor.cores\", \"1\")\n",
    "        .config(\"spark.executor.instances\", \"1\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"1\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CamlCATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caml import CamlCATE\n",
    "\n",
    "caml = CamlCATE(\n",
    "    df=df,\n",
    "    Y=\"y\",\n",
    "    T=\"d1\",\n",
    "    X=[c for c in df.columns if \"X\" in c],\n",
    "    W=[c for c in df.columns if \"W\" in c],\n",
    "    uuid=\"uuid\",\n",
    "    discrete_treatment=True,\n",
    "    discrete_outcome=False,\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nuissance Function AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caml.auto_nuisance_functions(\n",
    "    flaml_Y_kwargs={\"time_budget\": 10},\n",
    "    flaml_T_kwargs={\"time_budget\": 10},\n",
    "    use_ray=False,\n",
    "    use_spark=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit and ensemble CATE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caml.fit_validator(\n",
    "    subset_cate_models=[\n",
    "        \"LinearDML\",\n",
    "        \"NonParamDML\",\n",
    "        \"DML-Lasso3d\",\n",
    "        \"CausalForestDML\",\n",
    "        \"XLearner\",\n",
    "        \"DomainAdaptationLearner\",\n",
    "        \"SLearner\",\n",
    "        \"TLearner\",\n",
    "        \"DRLearner\",\n",
    "    ],\n",
    "    rscorer_kwargs={},\n",
    "    use_ray=False,\n",
    "    ray_remote_func_options_kwargs={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caml.validation_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CATE Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results = caml.validate(estimator=None, print_full_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refit best estimator on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caml.fit_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caml.final_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict CATEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"Out of sample\" predictions\n",
    "\n",
    "df_predictions = caml.predict(\n",
    "    out_of_sample_df=df,\n",
    "    out_of_sample_uuid=\"uuid\",\n",
    "    return_predictions=False,\n",
    "    join_predictions=True,\n",
    ")\n",
    "\n",
    "if df_backend == \"pyspark\":\n",
    "    df_predictions.show()\n",
    "else:\n",
    "    print(df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append to internal dataframe\n",
    "\n",
    "caml.predict(\n",
    "    out_of_sample_df=None,\n",
    "    out_of_sample_uuid=None,\n",
    "    join_predictions=True,\n",
    "    return_predictions=False,\n",
    ")\n",
    "\n",
    "caml.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CATE Rank Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"Out of sample\" predictions\n",
    "\n",
    "df_rank_ordered = caml.rank_order(\n",
    "    out_of_sample_df=df_predictions,\n",
    "    return_rank_order=False,\n",
    "    join_rank_order=True,\n",
    "    treatment_category=1,\n",
    ")\n",
    "\n",
    "df_rank_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append to internal dataframe\n",
    "\n",
    "caml.rank_order(\n",
    "    out_of_sample_df=None,\n",
    "    return_rank_order=False,\n",
    "    join_rank_order=True,\n",
    "    treatment_category=1,\n",
    ")\n",
    "\n",
    "caml.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CATE Visualization/Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_summary = caml.summarize(out_of_sample_df=df_rank_ordered, treatment_category=1)\n",
    "\n",
    "cate_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_summary = caml.summarize(out_of_sample_df=None, treatment_category=1)\n",
    "\n",
    "cate_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access my dataframe and estimator object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caml.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.score import EnsembleCateEstimator\n",
    "\n",
    "# Use this estimator object as pickled object for optimized inference\n",
    "final_estimator = caml.final_estimator\n",
    "\n",
    "if isinstance(final_estimator, EnsembleCateEstimator):\n",
    "    for model in final_estimator._cate_models:\n",
    "        print(model)\n",
    "        print(model._input_names)\n",
    "else:\n",
    "    print(final_estimator)\n",
    "    print(final_estimator._input_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
