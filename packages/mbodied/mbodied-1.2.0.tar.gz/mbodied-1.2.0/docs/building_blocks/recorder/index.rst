Recorder
==============

Overview
^^^^^^^^

Dataset `Recorder <https://github.com/mbodiai/embodied-agents/blob/main/mbodied/data/recording.py>`_ can record your conversation and the robot's actions to a dataset as you interact with/teach the robot. You can define any observation space and action space for the Recorder.

Here's an example of recording observation, instruction, and the output HandControl (x, y, z, r, p, y, grasp).

.. code-block:: python
    
    observation_space = spaces.Dict({
    'image': Image(size=(224, 224)).space(),
    'instruction': spaces.Text(1000)
    })
    action_space = HandControl().space()
    recorder = Recorder('example_recorder', out_dir='saved_datasets', observation_space=observation_space, action_space=action_space)

    # Every time robot makes a conversation or performs an action:
    recorder.record(observation={'image': image, 'instruction': instruction,}, action=hand_control)

The dataset is saved to ``./saved_datasets``. Learn more about augmenting, and finetuning with this dataset by filling out this `form <https://forms.gle/rv5rovK93dLucma37>`_.

Dataset Replayer
^^^^^^^^^^^^^^^^

The `Replayer <https://github.com/mbodiai/embodied-agents/blob/main/mbodied/data/replaying.py>`_ class is designed to process and manage data stored in HDF5 files generated by ``Recorder``. It provides a variety of functionalities, including reading samples, generating statistics, extracting unique items, and converting datasets for use with HuggingFace. The Replayer also supports saving specific images during processing and offers a command-line interface for various operations.

Here's a simple example on iterating through a dataset from Recorder with Replayer:

.. code-block:: python

    replayer = Replayer(path=str("path/to/dataset.h5"))
    for observation, action in replayer:
        ...
